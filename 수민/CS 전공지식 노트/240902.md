# 3장 운영체제
## 3.2. 메모리

### (1) 메모리 계층
```
[레지스터]
[캐시]
[메모리(RAM)/주기억장치]
[저장자치(HDD/SDD)/보조기억장치]
```
- 구성
    - 레지스터
        - CPU 안에 있는 작은 메모리. 휘발성, 속도 제일 빠르며 기억 용량 가장 적음
    - 캐시
        - L1, L2 캐시를 지칭. 휘발성, 속보 빠름, 적은 기억 용량
    - 주기억장치
        - RAM. 휘발성과 속도 보통. 기억 용량도 보통
    - 보조기억장치
        - HDD, SDD. 휘발성, 속도 낮음. 기억 용량은 많음
- 계층을 두는 이유: 경제성

- 캐시
    - 데이터를 미리 복사해 놓는 임시 저장소
    - 빠른 장치와 느린 장치에서 속도 차리에 따른 병목 현상을 줄이기 위한 메모리
    - 메모리와 CPU 사이의 속도 차이가 너무 큼 -> 중간에 레지스터 계층을 둬서 속도 차이를 해결 => 이때의 계층과 계층 사이를 캐싱 계층이라 함
        - ex. 캐시 메모리와 보조기억장치 사이의 주기억장치 -> 보조기억장치의 캐싱 계층
    - 지역성의 원리
        - 시간 지역성
            - 최근 사용한 데이터에 다시 접근하려는 특성
        - 공간 지역성
            - 최근 접근한 데이터를 이루고 있는 공간이나 그 가까운 공간에 접근하는 특성
    - 캐시히트와 캐시미스
        - 캐시히트: 캐시에서 원하는 데이터를 찾았음
            - 제어장치를 거쳐 데이터를 가져옴 -> 위치도 가깝고 CPU 내부 버스 기반 작동으로 속도 빠름
        - 캐시미스: 해당 데이터가 캐시에 없음 -> 주메모리로 가서 데이터를 찾아오는 것
            - 메모리에서 데이터를 가져옴 -> 시스템 버스 기반 작동으로 속도 느림
    - 캐시매핑
        - 캐시가 히트되기 위해 매핑하는 방법
        - CPU의 레지스터와 주 메모리(RAM) 간에 데이터를 주고받을 때 기반으로 설명
        - 분류
            - 직접 매핑: 처리가 빠르지만 충돌 발생이 잦음
            - 연관 매핑: 순서를 일치시키지 않고 관련 있는 캐시와 메모리를 매핑 -> 충돌 적지만 느린 속도
            - 집합 연관 매핑: 직접 매핑 + 연관 매핑. 순서는 일치시키지만 집합을 둬서 저장하기에 검색은 좀 더 효율적인 편.
    - 웹 브라우저의 캐시
        - 쿠키
            - 만료 기한이 있는 키-값 저장소
            - httponly 옵션을 거는 것이 중요(document.cookie로 볼 수 없게)
            - 보통 서버에서 만료 기한을 정함
        - 로컬 스토리지
            - 만료 기한이 없는 키-값 저장소
            - 웹 브라우저 닫아도 유지됨
            - 도메인 단위로 저장, 생성
            - 클라이언트에서만 수정 가능
        - 세션 스토리지
            - 만료 기한이 없는 키-값 저장소
            - 탭 단위로 세션 스토리지 생성 -> 탭 닫을 때 해당 데이터 삭제
            - 클라이언트에서만 수정 가능
    - 데이터베이스의 캐싱 계층
        - 메인 데이터베이스 위에 레디스(redis) 데이터베이스 계층을 캐싱 계층으로 둠 -> 성능 향상


### (2) 메모리 관리
- 가상메모리
    - 메모리 관리 기법의 하나
    - 컴퓨터가 실제로 이용 가능한 메모리 자원을 추상화하여 이를 사용하는 사용자들에게 매우 큰 메모리로 보이게 만드는 것
    - 가상 주소는 메모리관리장치(MMU)에 의해 실제 주소로 변환 -> 사용자는 실제 주소 의식할 필요X
    - TLB
        - 메모리와 CPU 사이에 있는 주소 변환을 위한 캐시 
        - 페이지 테이블에 있는 리스트를 보관하며 CPU가 페이지 테이블까지 가지 않도록 하여 속도 향상 시키는 캐시 계층
        - 가상 메모리는 가상 주소-실제 주소 매핑되어 있고, 페이지 테이블로 관리됨 -> 속도 향상을 위해 TLB를 사용
    - 스와핑
        - 사용하지 않을 땐 하드디스크, 필요할 땐 RAM -> 이 과정을 반복하여 RAM을 효과적으로 관리하는 것
        - FOR 페이지 폴트 방지
    - 페이지 폴트
        - 프로세스의 주소 공간에는 존재하지만 현재 RAM에는 없는 데이터에 접근했을 시 발생
        - 페이지 폴트 발생 시 스와핑
            - ㄱ. CPU는 물리 메모리 확인 -> 해당 페이지 없으면 트랩 발생시켜 운영체제에게 알림
            - ㄴ. 운영체제는 CPU 동작을 일시 정지
            - ㄷ. 운영체제는 페이지 테이블 확인 -> 가상 메모리에 페이지 존재 여부 확인 -> 없으면 프로세스 중단, 현재 물리 메모리에 비어 있는 프레임이 있는지 탐색 -> 물리 메모리에도 없으면 스와핑 발동
            - ㄹ. 비어 있는 프레임에 해당 페이지 로드 -> 페이지 테이블 최신화
            - ㅁ. 중단되었던 CPU 재시작

- 스레싱
    - 메모리의 페이지 폴트율이 높은 것을 의미 -> 컴퓨터의심각한 성능 저하 초래
    - 메모리에 너무 많은 프로세스가 동시에 올라감 -> 스와핑 많이 발생 -> 스레싱 발생
        - 왜냐? 페이지 폴트 발생 시 CPU 이용률이 낮아지고, 운영체제는 CPU가 노는 줄 알고 더 많은 프로세스를 메모리에 올림 -> 악순환 반복 -> 스레싱
    - 해결 방법
        - 작업 세트
            - 프로세스의 과거 사용 이력인 지역성을 통해 결정된 페이지 집합을 만들어서 미리 메모리에 로드
            - 탐색 비용과 스와핑 줄일 수 있음
        - PFF(Page Fault Frequency)
            - 페이지 폴트 빈도를 조절하는 방법 -> 상한선과 하한선을 만드는 방법
            - 상한선 도달 시 페이지 늘리고, 하한선 도달 시 페이지 줄임

- 메모리 할당
    - 연속 할당
        - 메모리에 연속적으로 공간을 할당
        - ㄱ. 고정 분할 방식
            - 메모리를 미리 나누어 관리하는 방식.
            - 메모리가 미리 나뉘어 있기에 융통성이 없는 편
            - 내부 단편화 발생
        - ㄴ. 가변 분할 방식
            - 매 시점 프로그램의 크기에 맞게 동적으로 메모리를 나누어 사용
            - 외부 단편화 발생 가능성 있음
            - 최초 적합, 최적 적합, 최악 적합

    - 불연속 할당
        - 현대 운여체제가 쓰는 방법
        - 페이징 기법
            - 동일한 크기의 페이지 단위로 나누어 메모리의 서로 다른 위치에 프로세스 할당
            - 주소 변환이 복잡해짐
        - 세그멘테이션
            - 의미 단위인 세그먼트로 나누는 방식
            - 공유와 보안 측면에서 굿, but 홀 크기가 균일하지 않은 문제 발생
        - 페이지드 세그멘테이션
            - 공유나 보안을 세그먼트로 나누고, 물리적 메모리는 페이지로 나눔

- 페이지 교체 알고리즘
    - 오프라인 알고리즘
        - 먼 미래에 참조되는 페이지와 현대 할당하는 페이지를 바꾸는 알고리즘. 
        - 가장 좋은 방법이지만 사용할 수 없는 알고리즘
        - 다른 알고리즘과의 성능 비교에 대한 기준을 제공할 뿐
    - FIFO(First In First Out)
        - 가장 먼저 온 페이지를 교체 영역에 가장 먼저 놓는 방법
    - LRU(Least Recentle Used)
        - 참조가 가장 오래된 페이지를 바꿈
        - 오래된 것을 파악하기 위헤 각 페이지마다 계수기, 스택 등을 둬야 하는 문제점
        - 보통 해시 테이블과 이중 연결 리스트, 두 개의 자료구조를 통해 구현
            - 해시 테이블 -> 이중 연결 리스트에서 빠르게 찾을 수 있도록 사용
            - 이중 연결 리스트 -> 한정된 메모리를 나타내는 데 사용
    - LFU(Least Frequently Used)
        - 가장 참조 횟수가 적은 페이지를 교체
        - 많이 사용되지 않은 것을 교체